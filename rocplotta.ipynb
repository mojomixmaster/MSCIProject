{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86612b0",
   "metadata": {},
   "source": [
    "# Final ROC Plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe5da2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "def load_and_prepare_data(data_path='padded_waveforms.parquet'):\n",
    "    \"\"\"\n",
    "    Load and prepare the data for modeling.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    # Load data\n",
    "    arr = ak.from_parquet(data_path)\n",
    "    df = pd.read_parquet(data_path)\n",
    "    \n",
    "    # Constants\n",
    "    electron_size = 58.5\n",
    "    padding_length = 500\n",
    "    \n",
    "    # Normalize data\n",
    "    def normalise_array(arr):\n",
    "        min_val = ak.min(arr, axis=-1)\n",
    "        max_val = ak.max(arr, axis=-1)\n",
    "        return (arr - min_val) / (max_val - min_val)\n",
    "    \n",
    "    normalised_times = normalise_array(arr['times'])\n",
    "    normalised_samples = normalise_array(arr['samples'])\n",
    "    \n",
    "    # Pad the data\n",
    "    def pad_to_max_length(array, max_length):\n",
    "        return ak.Array(\n",
    "            np.array(\n",
    "                [np.pad(sub_array, (0, max_length - len(sub_array)), 'constant') \n",
    "                 for sub_array in ak.to_list(array)]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Get the maximum length\n",
    "    times_lengths = ak.num(normalised_times, axis=1)\n",
    "    max_time_length = ak.max(times_lengths)\n",
    "    samples_lengths = ak.num(normalised_samples, axis=1)\n",
    "    max_samples_length = ak.max(samples_lengths)\n",
    "    \n",
    "    # Pad times and samples\n",
    "    padded_times = np.array(pad_to_max_length(normalised_times, max_time_length))\n",
    "    padded_samples = np.array(pad_to_max_length(normalised_samples, max_samples_length))\n",
    "    \n",
    "    # Combine for CNN input\n",
    "    X_combined = np.concatenate([padded_times, padded_samples], axis=1)\n",
    "    \n",
    "    # Add zero-padding on each side of the data\n",
    "    X_padded = np.pad(X_combined, ((0, 0), (padding_length, padding_length)), \n",
    "                       mode='constant', constant_values=0)\n",
    "    \n",
    "    # Create feature set for BDT and RF\n",
    "    bdt_features = df[['area', 'max_pulse_height', 'r', 'S2_width', 'x', 'y']]\n",
    "    \n",
    "    # Get labels and normalize area\n",
    "    y = np.array(arr['label'])\n",
    "    normalized_area = np.array(arr['area'] / electron_size)\n",
    "    \n",
    "    # Calculate weights (if you have a specific weighting scheme)\n",
    "    # For simplicity, we're using uniform weights here\n",
    "    weights = np.ones(len(y))\n",
    "    \n",
    "    # Split data\n",
    "    X_cnn_train, X_cnn_test, X_bdt_train, X_bdt_test, y_train, y_test, area_train, area_test, weights_train, weights_test = train_test_split(\n",
    "        X_padded, bdt_features, y, normalized_area, weights, test_size=0.25, random_state=seed_value\n",
    "    )\n",
    "    \n",
    "    # Make sure the y arrays are the right type\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Reshape CNN input to have a channel dimension\n",
    "    X_cnn_train_reshaped = X_cnn_train.reshape(X_cnn_train.shape[0], X_cnn_train.shape[1], 1)\n",
    "    X_cnn_test_reshaped = X_cnn_test.reshape(X_cnn_test.shape[0], X_cnn_test.shape[1], 1)\n",
    "    \n",
    "    print(f\"Data prepared. Training samples: {len(X_cnn_train)}, Test samples: {len(X_cnn_test)}\")\n",
    "    \n",
    "    return {\n",
    "        'X_cnn_train': X_cnn_train_reshaped,\n",
    "        'X_cnn_test': X_cnn_test_reshaped,\n",
    "        'X_bdt_train': X_bdt_train,\n",
    "        'X_bdt_test': X_bdt_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'weights_train': weights_train,\n",
    "        'weights_test': weights_test,\n",
    "        'area_test': area_test\n",
    "    }\n",
    "\n",
    "def build_and_train_models(data):\n",
    "    \"\"\"\n",
    "    Build and train the CNN, BDT, and RF models.\n",
    "    \"\"\"\n",
    "    print(\"Building and training models...\")\n",
    "    models = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    # 1. CNN Model with exact configuration from provided code\n",
    "    print(\"Training CNN model...\")\n",
    "    \n",
    "    # Setup callbacks for CNN\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.005,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [early_stopping, lr_scheduler]\n",
    "    \n",
    "    # Define the CNN model with the exact architecture provided\n",
    "    convoNN = keras.Sequential([\n",
    "        # First 1D convolution layer\n",
    "        keras.layers.Conv1D(\n",
    "            filters=64, \n",
    "            kernel_size=100, \n",
    "            activation='relu', \n",
    "            padding='same', \n",
    "            kernel_regularizer=regularizers.l2(0.001), \n",
    "            input_shape=(data['X_cnn_train'].shape[1], 1)\n",
    "        ),\n",
    "        keras.layers.MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second 1D convolution layer\n",
    "        keras.layers.Conv1D(\n",
    "            filters=154, \n",
    "            kernel_size=60, \n",
    "            padding='same', \n",
    "            activation='relu'\n",
    "        ),\n",
    "        keras.layers.MaxPooling1D(pool_size=2),\n",
    "        # Dropout(0.3),  # Commented out as in original code\n",
    "        \n",
    "        # Flatten layer\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(96, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with legacy Adam optimizer\n",
    "    optimizer = legacy.Adam(learning_rate=5.762e-4)\n",
    "    convoNN.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model with callbacks\n",
    "    history = convoNN.fit(\n",
    "        data['X_cnn_train'], \n",
    "        data['y_train'], \n",
    "        sample_weight=data['weights_train'],\n",
    "        epochs=15, \n",
    "        batch_size=323, \n",
    "        validation_split=0.2, \n",
    "        callbacks=callbacks, \n",
    "        verbose=1  # Set to 1 to show progress\n",
    "    )\n",
    "    \n",
    "    # Get CNN predictions\n",
    "    predictions['cnn'] = convoNN.predict(data['X_cnn_test'], verbose=0)\n",
    "    models['cnn'] = convoNN\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], color='#E63946', linewidth=2.5, label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], color='#457B9D', linewidth=2.5, label='Validation')\n",
    "    plt.ylabel('Accuracy', fontsize=18)\n",
    "    plt.xlabel('Epoch', fontsize=18)\n",
    "    plt.legend(loc='lower right', fontsize=18)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], color='#E63946', linewidth=2.5, label='Train')\n",
    "    plt.plot(history.history['val_loss'], color='#457B9D', linewidth=2.5, label='Validation')\n",
    "    plt.ylabel('Loss', fontsize=18)\n",
    "    plt.xlabel('Epoch', fontsize=18)\n",
    "    if len(history.history['loss']) > 10:\n",
    "        plt.xlim(0, 10)\n",
    "    plt.legend(loc='upper right', fontsize=18)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_validation_metrics.png', dpi=1200)\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. XGBoost (BDT) Model\n",
    "    print(\"Training BDT model...\")\n",
    "    dtrain = xgb.DMatrix(data['X_bdt_train'], label=data['y_train'], weight=data['weights_train'])\n",
    "    dtest = xgb.DMatrix(data['X_bdt_test'], label=data['y_test'])\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 3,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": 0.02,\n",
    "        \"max_depth\": 3,\n",
    "        \"seed\": seed_value\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=100,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # Get BDT predictions\n",
    "    predictions['bdt'] = bst.predict(dtest)\n",
    "    models['bdt'] = bst\n",
    "    \n",
    "    # 3. Random Forest Model\n",
    "    print(\"Training RF model...\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=20, \n",
    "        min_samples_split=10,\n",
    "        max_features='sqrt', \n",
    "        random_state=seed_value\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(data['X_bdt_train'], data['y_train'])\n",
    "    \n",
    "    # Get RF predictions\n",
    "    predictions['rf'] = rf_model.predict_proba(data['X_bdt_test'])\n",
    "    models['rf'] = rf_model\n",
    "    \n",
    "    print(\"All models trained.\")\n",
    "    return models, predictions, data['y_test']\n",
    "\n",
    "def plot_roc_curves(y_test, cnn_probs, bdt_probs, rf_probs, event_types=['gate', 'cathode'], save_plots=True):\n",
    "    \"\"\"\n",
    "    Plot ROC curves comparing CNN, BDT, and RF models for event discrimination.\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = [12, 8]\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    \n",
    "    models = {\n",
    "        'CNN': {'probs': cnn_probs, 'color': 'black', 'linestyle': '-', 'linewidth': 2},\n",
    "        'BDT': {'probs': bdt_probs, 'color': 'darkblue', 'linestyle': '-', 'linewidth': 2},\n",
    "        'RF': {'probs': rf_probs, 'color': 'cornflowerblue', 'linestyle': '-', 'linewidth': 2}\n",
    "    }\n",
    "    \n",
    "    # Plot combined ROC curves for each event type\n",
    "    for event_type in event_types:\n",
    "        # Set up the event-specific data\n",
    "        if event_type == 'gate':\n",
    "            event_idx = 1\n",
    "            title = 'Tritium vs Gate'\n",
    "            xlabel = 'Gate Leakage (False Positive Rate)'\n",
    "            filename = 'ROC_curves_combined_gate.png'\n",
    "        else:  # cathode\n",
    "            event_idx = 0\n",
    "            title = 'Tritium vs Cathode'\n",
    "            xlabel = 'Cathode Leakage (False Positive Rate)'\n",
    "            filename = 'ROC_curves_combined_cathode.png'\n",
    "        \n",
    "        # Create binary classification mask (tritium vs the specific event type)\n",
    "        mask = (y_test == 2) | (y_test == event_idx)\n",
    "        binary_labels = np.where(y_test[mask] == 2, 1, 0)  # Tritium = 1, Other = 0\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot each model's ROC curve\n",
    "        for model_name, model_info in models.items():\n",
    "            # Get tritium probabilities for binary classification\n",
    "            tritium_probs = model_info['probs'][mask, 2]\n",
    "            \n",
    "            # Calculate ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(binary_labels, tritium_probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot the ROC curve\n",
    "            plt.plot(\n",
    "                fpr, tpr, \n",
    "                label=f'{model_name} (AUC = {roc_auc:.2f})', \n",
    "                color=model_info['color'],\n",
    "                linestyle=model_info['linestyle'],\n",
    "                linewidth=model_info['linewidth']\n",
    "            )\n",
    "        \n",
    "        # Add plot labels and styling\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel('Tritium Acceptance (True Positive Rate)')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(False)\n",
    "        \n",
    "        # Save the figure if requested\n",
    "        if save_plots:\n",
    "            plt.savefig(filename, dpi=1500, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Also create individual plots for each model\n",
    "        if save_plots:\n",
    "            for model_name, model_info in models.items():\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "                # Get tritium probabilities for binary classification\n",
    "                tritium_probs = model_info['probs'][mask, 2]\n",
    "                \n",
    "                # Calculate ROC curve and AUC\n",
    "                fpr, tpr, _ = roc_curve(binary_labels, tritium_probs)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                \n",
    "                # Plot single model ROC curve\n",
    "                plt.plot(\n",
    "                    fpr, tpr, \n",
    "                    label=f'{model_name} (AUC = {roc_auc:.2f})', \n",
    "                    color=model_info['color'],\n",
    "                    linestyle=model_info['linestyle'],\n",
    "                    linewidth=model_info['linewidth']\n",
    "                )\n",
    "                \n",
    "                # Add plot labels and styling\n",
    "                plt.xlabel(xlabel)\n",
    "                plt.ylabel('Tritium Acceptance (True Positive Rate)')\n",
    "                plt.legend(loc='lower right')\n",
    "                plt.grid(False)\n",
    "                \n",
    "                # Save the individual plot\n",
    "                plt.savefig(f'ROC_curve{model_name}_{event_type}.png', dpi=1500, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "def main(data_path='padded_waveforms.parquet'):\n",
    "    \"\"\"\n",
    "    Main function to run the full pipeline.\n",
    "    \"\"\"\n",
    "    # Load and prepare data\n",
    "    data = load_and_prepare_data(data_path)\n",
    "    \n",
    "    # Build and train models\n",
    "    models, predictions, y_test = build_and_train_models(data)\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plot_roc_curves(\n",
    "        y_test,\n",
    "        predictions['cnn'],\n",
    "        predictions['bdt'],\n",
    "        predictions['rf'],\n",
    "        event_types=['gate', 'cathode'],\n",
    "        save_plots=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your data path\n",
    "    main(data_path='padded_waveforms.parquet')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
