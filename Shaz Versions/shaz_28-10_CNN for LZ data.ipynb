{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acdc8fd7-d662-4654-ac7f-0ab6a0c821a0",
   "metadata": {},
   "source": [
    "Here is some code where I am messing around with building a convolutional neural network using some examples from the internet. I've writted notes about how this needs to be modified for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20267600-fa6b-4d98-92c5-b5c4672c0440",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456c6b1-26b8-4765-a173-5af0e693668f",
   "metadata": {},
   "source": [
    "Install tensorflow in your conda environment. Note that you need to have numpy-1.23.1. When I did this, I had to manually uninstall numpy-1.24.3 then install numpy-1.23.1, before installing tensorflow. The tensorflow install failed to install numpy-1.23.1, itself, even though it told me it was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a493a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.23.1\n",
      "Uninstalling numpy-1.23.1:\n",
      "  Successfully uninstalled numpy-1.23.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 189, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\", line 91, in run\n",
      "    uninstall_pathset.commit()\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 456, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 296, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 205, in cleanup\n",
      "    rmtree(ensure_text(self._path))\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_vendor\\six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 129, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors,\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\shutil.py\", line 740, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\shutil.py\", line 613, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\shutil.py\", line 618, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\44738\\anaconda3\\lib\\shutil.py\", line 616, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\44738\\\\anaconda3\\\\Lib\\\\site-packages\\\\~1mpy\\\\.libs\\\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.1\n",
      "  Using cached numpy-1.23.1-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.23.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.6.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c53be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\44738\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.67.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (20.9)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.1)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: setuptools in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\44738\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7dce79-4f35-42e9-bcfd-dec4973eec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "\n",
    "import hist\n",
    "from hist import Hist, axis\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7cc9b",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2ee6c-b369-480d-9360-ee447b268da5",
   "metadata": {},
   "source": [
    "Download the mnist data base from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz then load in the data. For me, keras wasn't able to automatically download the data so I had to go to the url and download the data by hand before loading the data, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389b570b-e5ac-41e0-892f-a6a63a1115df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runID',\n",
       " 'eventID',\n",
       " 'times',\n",
       " 'samples',\n",
       " 'length',\n",
       " 'area',\n",
       " 'max_pulse_height',\n",
       " 'ext_elec',\n",
       " 'x',\n",
       " 'y',\n",
       " 'r',\n",
       " 'S2_width',\n",
       " 'label',\n",
       " 'type',\n",
       " 'weights_no_gas',\n",
       " 'chonkers']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "font = {'weight' : 'normal','size'   : 22}\n",
    "plt.rc('font', **font)\n",
    "data_path = 'padded_waveforms.parquet'\n",
    "arr = ak.from_parquet(data_path)\n",
    "ak.fields(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b97c7-0a56-4114-9dc7-bfbee19c8b35",
   "metadata": {},
   "source": [
    "The data are 2D greyscale images of handwritten numbers with intensity in the range 0-255. The data must be rescaled by dividing by 255, then flattened into 1D arrays.\n",
    "\n",
    "In our case, we will be using 1D 'images' and the range will be between 0 and the maximum height reached within any one of the pulses. We don't know what this is ahead of time; you'll have to find the maximum then divide all the images by that number. I think we will also need to pad the arrays to make them the same length, since each pulse will have a variable number of samples. I would start by adding zeroes evenly to the front and back of the array. I'm not sure if the way we do this could introduce some difficulties in learning for the CNN. We should think about this a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a18898-be31-42e3-830a-933e97d7e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0.000909, 0.00182, 0.00273, 0.00364, ..., 0.997, 0.998, 0.999, 1], ...]\n",
      "[[0.00238, 0.00212, 0.00198, 0.00223, ..., 0.00251, 0.00211, 0.00133, 0], ...]\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Assuming 'times' and 'samples' are the column names\n",
    "# Normalize each array in the 'times' and 'samples' columns\n",
    "\n",
    "# Function to normalize arrays to values between 0 and 1\n",
    "def normalize_array(arr):\n",
    "    min_val = ak.min(arr, axis=-1)\n",
    "    max_val = ak.max(arr, axis=-1)\n",
    "    return (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "# Apply normalization to each column\n",
    "normalized_times = normalize_array(arr['times'])\n",
    "normalized_samples = normalize_array(arr['samples'])\n",
    "\n",
    "\n",
    "\n",
    "# Print or inspect the results\n",
    "print(normalized_times)\n",
    "print(normalized_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8815f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape: (7782, 3656)\n",
      "labels shape: (7782,)\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Determine the maximum length in both normalized arrays\n",
    "max_length = max(ak.max(ak.num(normalized_times, axis=-1)), ak.max(ak.num(normalized_samples, axis=-1)))\n",
    "\n",
    "# Pad each array to the same maximum length\n",
    "padded_times = ak.fill_none(ak.pad_none(normalized_times, target=max_length, axis=-1), 0)\n",
    "padded_samples = ak.fill_none(ak.pad_none(normalized_samples, target=max_length, axis=-1), 0)\n",
    "\n",
    "# Convert padded arrays to numpy and concatenate\n",
    "padded_times_np = ak.to_numpy(padded_times)\n",
    "padded_samples_np = ak.to_numpy(padded_samples)\n",
    "\n",
    "X_combined = np.concatenate([padded_times_np, padded_samples_np], axis=1)\n",
    "print(\"X_combined shape:\", X_combined.shape)\n",
    "\n",
    "labels = arr['label']\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489ebbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5836, 3656)\n",
      "X_test shape: (1946, 3656)\n",
      "y_train shape: (5836,)\n",
      "y_test shape: (1946,)\n"
     ]
    }
   ],
   "source": [
    "# Split X_combined and labels into 25% training and 75% test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca8dca8-1a06-4e8a-9199-46e97408abdf",
   "metadata": {},
   "source": [
    "# Sequential fully-connected neural network with only input and output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20275ce-6d79-44e8-837e-db569038046e",
   "metadata": {},
   "source": [
    "This is a sequential fully-connected neural network with only input and output layers. The input shape is (784,) because each 28x28 image has been flattened into a 784x1 tensor. Each element of the tensor is fed into one of the 784 neurons of the input layer. The output shape is 10 because there are 10 different numbers that can be written in the image: 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9. The term \"sequential\" indicates the model is a plain stack of layers, which works in a basic scenario where every layer has a single input tensor and a single output tensor. The term \"fully-connected\" refers to the fact that each one of the 784 input neurons is connected to each one of the 10 output neurons. Generally, the activation function for the output layer is a sigmoid that scales the output of each neuron to within the range 0-1. This makes it appear to be a probability, but I think it's not a probability and we shouldn't call it that.\n",
    "\n",
    "The configuration described above can be adapted to our case. The input shape will be the paded length of the waveforms, the output shape will be 3 for a 0 (signal-like), 1 (gate-like), or 2 (cathode-like) S2.\n",
    "\n",
    "Some resources for learning or remembering what a neural network does are: https://victorzhou.com/blog/intro-to-neural-networks/ (simple description of a neural network) and https://keras.io/guides/sequential_model/ (basic description of how to write the code using keras). You may already have experience with this from your courses - I'm not sure what they teach these days - but it's not a big deal if you have no experience because there are lots of resources online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689ede31-4bba-44c2-94d0-4eb14452983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3)                 10971     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10971 (42.86 KB)\n",
      "Trainable params: 10971 (42.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simpleNN = keras.Sequential([\n",
    "    keras.layers.Dense(3,input_shape=(3656,),activation='sigmoid')\n",
    "])\n",
    "\n",
    "simpleNN.summary()\n",
    "\n",
    "#this sets up our sequential fully-connected neural network with only an input and output layer\n",
    "#keras.Sequential() creastes the model- layers stached one after another linearky\n",
    "#the 10 defines a fully connected dense layer with 10 neurons\n",
    "#input_shape(784,)- just says the shape of the input data (784 pixels)\n",
    "#sigmoid just applies the sigmoid activation function to each neuron0 this sigmoid function outputs values between 0 and 1\n",
    "#the last command just prints a summary of the models architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfa577-af4a-4269-8d74-f46b050166e6",
   "metadata": {},
   "source": [
    "The loss function for multi-class classification should be sparse categorical crossentropy. This will work for our case as well, since we have 3 categories. We could also try a case were we have an output shape of 2  with 0 = signal-like and 1 = gate/cathode-like, using binary crossentropy. Was there any similar issue with the hyperparameters for the multiclass boosted decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcd3ca2-fc3e-42f4-8c7f-050bd8f9673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleNN.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "#this function prepares the model for training\n",
    "#optimiser- updates weights of the network based on the gradients calculated via backpropagation\n",
    "#loss- tells the network how wrong the predictions are\n",
    "#metrics- used to tell you the perfromance of the model here we specify the accuracy as the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fcee5-783f-4886-b9a8-cebcce307150",
   "metadata": {},
   "source": [
    "One epoch corresponds to running the data through the neural network, calculating the loss, and reweighting the model. We will have to weight the samples evenly across S2 size, like  we did for the boosted decision tree. I think this is done by setting the paramter sample_weight equal to your sample weights in the fit function, below. We will also have to decide how many epochs to use by plotting accuracy vs epoch, as you've done for the boosted decision tree, and comparing the accuracy of the test and training datasets, which should be the ~same at the end if you aren't overtraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad98483-ae9c-4f32-b57c-a2b45e1dab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.3832 - accuracy: 0.8367\n",
      "Epoch 2/5\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8571\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8609\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8614\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dc45e7a9a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleNN.fit(X_train,y_train,epochs=5)\n",
    "# here we train the data, epochs is the numbers of times the data gets trained\n",
    "#X_train_flattened- input training data\n",
    "#y_train is the true value of the data that we use for comparison and what the model tried to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be80c2fe-bbad-4f12-8ebd-bc0ce02e56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3483726680278778, 0.8581706285476685]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleNN.evaluate(X_test,y_test)\n",
    "#this evaluates the trained model\n",
    "#X_test_flattened- test input data\n",
    "#y_test: true labels for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ff3e-713b-4d0a-b0e8-fcf933a1048c",
   "metadata": {},
   "source": [
    "It's also nice to plot a confusion matrix to understand what is getting misclassified. This might be good to do making cuts on S2 size, especially if the accuracy vs epoch plot shows that some S2 sizes are improving while others are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90bd8a2f-9749-4775-9b4f-280abfeabaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.52602935, 0.0012083 , 0.8971098 ], dtype=float32), 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = simpleNN.predict(X_test)\n",
    "y_predicted_label = [np.argmax(i) for i in y_predicted]\n",
    "\n",
    "y_predicted[0], y_predicted_label[0]\n",
    "\n",
    "#first line produces predicted probabilities for each class i.e digits 0-9 for each image\n",
    "#the ouput y_predicted would create an erray corresponding to all the pixels in the image giving it a probability (i.e. 784 pixels with 0-9 digit)\n",
    "#2nd line line converts the probability array into a class label\n",
    "#np.argmax{i}, finds the index of the highest value in each array- this index corresponds to the predicted class (digit)\n",
    "#y_predicted_label[0]- returns the predicted label for the first test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3d2a346-fe0e-4119-bcfa-584ce43ced9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(59.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_label),\n",
    "           annot=True, \n",
    "           fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "\n",
    "#line sets up a new figure for the plot with size 10* 7 inches\n",
    "#sn.heatmap creates a matrix which shows you how many times the predicted labels match the true labels\n",
    "#tf.math.confusion_matrix() generates this confusion matrix using tensor flow\n",
    "#the labels within the matrix show you your true result in y axis and predicted result in x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb107e-451b-4032-9fb1-c9f69f06b887",
   "metadata": {},
   "source": [
    "# Adding a hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6268434-9025-4e01-b738-8125297172a7",
   "metadata": {},
   "source": [
    "Adding a hidden layer can increase performance but will take longer to run. We'll have to think about how to optimize the number of hidden layers and the number of neurons in each hidden layer. Below, there is one hidden layer with 100 neurons. The activation function is a rectified linear unit (ReLU), which helps to improve performance. Hidden layers usually have ReLU or Leaky ReLU functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d819f1af-ce44-4ccd-9fdc-e71fba439276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 100)               365700    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366003 (1.40 MB)\n",
      "Trainable params: 366003 (1.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hiddenNN = keras.Sequential([\n",
    "    keras.layers.Dense(100,input_shape=(3656,),activation='relu'),\n",
    "    keras.layers.Dense(3,activation='sigmoid')\n",
    "])\n",
    "hiddenNN.summary()\n",
    "\n",
    "#keras.sequential([])- creates a sequential model\n",
    "#first layer is the hidden layer, second layer is the output layer\n",
    "#layer 1, is fully connected with 100 neurons, with input of 784 length arrays\n",
    "#layer 2, is output layer, which is a fully connected layer with 10 neurons\n",
    "#then we print out the summary of hte model shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b9294a8-c067-4be5-a84c-59cbb1d86e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183/183 [==============================] - 2s 6ms/step - loss: 0.3651 - accuracy: 0.8463\n",
      "Epoch 2/5\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3079 - accuracy: 0.8681\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.8765\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.2782 - accuracy: 0.8806\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.2657 - accuracy: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dc45e48d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddenNN.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "hiddenNN.fit(X_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a36946e-d314-4cae-9c17-94e4ccbbeba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28996115922927856, 0.8802672028541565]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddenNN.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec40ac1-2fc4-4656-9c16-4d21e8528752",
   "metadata": {},
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d588c1-d229-4e14-b537-421a0df293f7",
   "metadata": {},
   "source": [
    "Convolutional layers should improve the accuracy further but will even longer to run. You should try to understand what filters, pooling, and kernal size are. These are the hyperparameters you need to mess around with, as well as the number of convolutional layers. The filters will be used to look for certain features of the S2 waveforms so I think the kernal size should be decided based on the size of features you are trying to select. Here is a descriptive link: https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network#:~:text=A%20convolutional%20neural%20network%20is,classify%20objects%20in%20an%20image. This made my computer start to overheat, hence the desire to use a gpu, but maybe we are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2d1b4a-208f-4ffc-af46-d62ea20c5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convoNN = keras.Sequential([\n",
    "#    keras.layers.Conv2D(filters=28,kernel_size=(3,3),activation='relu', input_shape=(28,28,1)),\n",
    "#    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "#    keras.layers.Conv2D(filters=64,kernel_size=(3, 3),activation='relu'),\n",
    "#    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "#    keras.layers.Flatten(),\n",
    "#    keras.layers.Dense(64, activation='relu'),\n",
    "#    keras.layers.Dense(3, activation='softmax')\n",
    "#])\n",
    "\n",
    "\n",
    "#CNN with 7 layers\n",
    "#the first two Conv2D extract spatial features from the image- i.e. there will be 28 filters that will scan the image for patterns, each filter extracts different features from the image (e.g.textures, edges)\n",
    "#max Pooling layer performs down-sampling to resduce spatial dimensions\n",
    "#(2,2) specifies a pooling window which means the layer will take the max value from every 2*2 region\n",
    "#flatten layer converts information from 2D map to a 1D vector\n",
    "#64 layer is a dense layer with 64 neurons\n",
    "#10 layer is our 10 neuron layer that provides a class (digit 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6730c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Adjusted model to work with 1D input data\n",
    "convoNN = keras.Sequential([\n",
    "    # First 1D convolution layer\n",
    "    keras.layers.Conv1D(filters=28, kernel_size=3, activation='relu', input_shape=(3656, 1)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Second 1D convolution layer\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Flatten layer to connect to dense layers\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')  # Adjust output size for the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "convoNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1bf8540-3f15-48d9-a649-be7804e567c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "convoNN.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "040b4dad-805d-4b93-b8f7-1097050fbd05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183/183 [==============================] - 18s 92ms/step - loss: 0.3546 - accuracy: 0.8424\n",
      "Epoch 2/5\n",
      "183/183 [==============================] - 18s 98ms/step - loss: 0.3086 - accuracy: 0.8660\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - 18s 98ms/step - loss: 0.2799 - accuracy: 0.8799\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - 23s 124ms/step - loss: 0.2631 - accuracy: 0.8862\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - 22s 121ms/step - loss: 0.2379 - accuracy: 0.8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dc4798bdf0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convoNN.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21d1e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 2s 24ms/step - loss: 0.2960 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29600489139556885, 0.8833504915237427]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to add a channel dimension for the 1D CNN\n",
    "X_test_reshaped = X_test.reshape(-1, 3656, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "convoNN.evaluate(X_test_reshaped, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec8a8eb5-69c9-4d4f-8546-e9f849a64fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convoNN.evaluate(X_test_flattened,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d1821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad7739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
